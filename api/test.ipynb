{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1061ac93-219b-4449-9034-16f55a4a1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f6c9a2-0483-45ec-a1a7-6ea23c2bbceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mass': tensor([56.8733], device='cuda:0'), 'height': tensor([1.6438], device='cuda:0'), 'chest': tensor([0.8746], device='cuda:0'), 'waist': tensor([0.7652], device='cuda:0'), 'hips': tensor([0.9547], device='cuda:0')}\n",
      "{'mass': tensor([92.7684], device='cuda:0'), 'height': tensor([1.6489], device='cuda:0'), 'chest': tensor([1.1550], device='cuda:0'), 'waist': tensor([1.0804], device='cuda:0'), 'hips': tensor([1.1465], device='cuda:0')}\n",
      "{'mass': tensor([73.0017], device='cuda:0'), 'height': tensor([1.7156], device='cuda:0'), 'chest': tensor([1.0081], device='cuda:0'), 'waist': tensor([0.8915], device='cuda:0'), 'hips': tensor([0.9630], device='cuda:0')}\n",
      "{'mass': tensor([85.1441], device='cuda:0'), 'height': tensor([1.6399], device='cuda:0'), 'chest': tensor([1.0893], device='cuda:0'), 'waist': tensor([1.0081], device='cuda:0'), 'hips': tensor([1.1323], device='cuda:0')}\n",
      "{'mass': tensor([91.3231], device='cuda:0'), 'height': tensor([1.7975], device='cuda:0'), 'chest': tensor([1.1264], device='cuda:0'), 'waist': tensor([0.9967], device='cuda:0'), 'hips': tensor([1.0185], device='cuda:0')}\n",
      "{'mass': tensor([93.4046], device='cuda:0'), 'height': tensor([1.6688], device='cuda:0'), 'chest': tensor([1.1512], device='cuda:0'), 'waist': tensor([1.0591], device='cuda:0'), 'hips': tensor([1.1580], device='cuda:0')}\n",
      "{'mass': tensor([73.2150], device='cuda:0'), 'height': tensor([1.7844], device='cuda:0'), 'chest': tensor([1.0040], device='cuda:0'), 'waist': tensor([0.8290], device='cuda:0'), 'hips': tensor([0.9836], device='cuda:0')}\n",
      "{'mass': tensor([85.5131], device='cuda:0'), 'height': tensor([1.6912], device='cuda:0'), 'chest': tensor([1.0784], device='cuda:0'), 'waist': tensor([0.9752], device='cuda:0'), 'hips': tensor([1.1255], device='cuda:0')}\n",
      "{'mass': tensor([69.9724], device='cuda:0'), 'height': tensor([1.7309], device='cuda:0'), 'chest': tensor([0.9913], device='cuda:0'), 'waist': tensor([0.8567], device='cuda:0'), 'hips': tensor([0.9488], device='cuda:0')}\n",
      "{'mass': tensor([55.1111], device='cuda:0'), 'height': tensor([1.6819], device='cuda:0'), 'chest': tensor([0.8692], device='cuda:0'), 'waist': tensor([0.7547], device='cuda:0'), 'hips': tensor([0.9244], device='cuda:0')}\n",
      "{'mass': tensor([77.5276], device='cuda:0'), 'height': tensor([1.7665], device='cuda:0'), 'chest': tensor([1.0437], device='cuda:0'), 'waist': tensor([0.8468], device='cuda:0'), 'hips': tensor([1.0261], device='cuda:0')}\n",
      "{'mass': tensor([78.5128], device='cuda:0'), 'height': tensor([1.7636], device='cuda:0'), 'chest': tensor([1.0506], device='cuda:0'), 'waist': tensor([0.8563], device='cuda:0'), 'hips': tensor([1.0238], device='cuda:0')}\n",
      "{'mass': tensor([78.0970], device='cuda:0'), 'height': tensor([1.6464], device='cuda:0'), 'chest': tensor([1.0314], device='cuda:0'), 'waist': tensor([0.9385], device='cuda:0'), 'hips': tensor([1.0946], device='cuda:0')}\n",
      "{'mass': tensor([72.9252], device='cuda:0'), 'height': tensor([1.6413], device='cuda:0'), 'chest': tensor([0.9865], device='cuda:0'), 'waist': tensor([0.8601], device='cuda:0'), 'hips': tensor([1.0824], device='cuda:0')}\n",
      "{'mass': tensor([86.0884], device='cuda:0'), 'height': tensor([1.8505], device='cuda:0'), 'chest': tensor([1.0804], device='cuda:0'), 'waist': tensor([0.9212], device='cuda:0'), 'hips': tensor([1.0225], device='cuda:0')}\n",
      "{'mass': tensor([65.0033], device='cuda:0'), 'height': tensor([1.6737], device='cuda:0'), 'chest': tensor([0.9377], device='cuda:0'), 'waist': tensor([0.8173], device='cuda:0'), 'hips': tensor([1.0060], device='cuda:0')}\n",
      "{'mass': tensor([71.0164], device='cuda:0'), 'height': tensor([1.7509], device='cuda:0'), 'chest': tensor([0.9905], device='cuda:0'), 'waist': tensor([0.8429], device='cuda:0'), 'hips': tensor([0.9589], device='cuda:0')}\n",
      "{'mass': tensor([71.6885], device='cuda:0'), 'height': tensor([1.6580], device='cuda:0'), 'chest': tensor([0.9785], device='cuda:0'), 'waist': tensor([0.8797], device='cuda:0'), 'hips': tensor([1.0513], device='cuda:0')}\n",
      "{'mass': tensor([54.1918], device='cuda:0'), 'height': tensor([1.6940], device='cuda:0'), 'chest': tensor([0.8588], device='cuda:0'), 'waist': tensor([0.7484], device='cuda:0'), 'hips': tensor([0.9101], device='cuda:0')}\n",
      "{'mass': tensor([76.5163], device='cuda:0'), 'height': tensor([1.7973], device='cuda:0'), 'chest': tensor([1.0267], device='cuda:0'), 'waist': tensor([0.8633], device='cuda:0'), 'hips': tensor([0.9908], device='cuda:0')}\n",
      "{'mass': tensor([73.6003], device='cuda:0'), 'height': tensor([1.7714], device='cuda:0'), 'chest': tensor([1.0090], device='cuda:0'), 'waist': tensor([0.8373], device='cuda:0'), 'hips': tensor([0.9807], device='cuda:0')}\n",
      "{'mass': tensor([72.6759], device='cuda:0'), 'height': tensor([1.7830], device='cuda:0'), 'chest': tensor([1.0005], device='cuda:0'), 'waist': tensor([0.8268], device='cuda:0'), 'hips': tensor([0.9875], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for i in range(22):\n",
    "    data = np.load(f\"../samples/shapy_fit/img_{i:02}.npz\", allow_pickle=True)\n",
    "    betas = torch.from_numpy(data['betas']).to('cuda').unsqueeze(0)\n",
    "    print(data[\"measurements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b8a5e63-8f8f-4358-ae2c-9437008af14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fname',\n",
       " 'joints',\n",
       " 'vertices',\n",
       " 'v_shaped',\n",
       " 'faces',\n",
       " 'global_rot',\n",
       " 'raw_global_rot',\n",
       " 'body_pose',\n",
       " 'raw_body_pose',\n",
       " 'betas',\n",
       " 'camera',\n",
       " 'measurements',\n",
       " 'proj_joints',\n",
       " 'shift_x',\n",
       " 'shift_y',\n",
       " 'transl',\n",
       " 'focal_length_in_mm',\n",
       " 'focal_length_in_px',\n",
       " 'center',\n",
       " 'sensor_width']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e477b94-0d7e-46e9-be77-c04ded572ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5223857 , -0.00772137,  0.19604209], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"camera\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83591c5d-fc90-412c-96c4-e9b500e16334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "\n",
    "from threadpoolctl import threadpool_limits\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import trimesh\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import smplx\n",
    "from body_measurements import BodyMeasurements\n",
    "from attributes.utils.renderer import Renderer\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure(\n",
    "    beta_sets: list[torch.Tensor],\n",
    "    gender: str = 'neutral',\n",
    "    num_betas: int = 10,\n",
    "    # demo_output_folder: os.PathLike = 'demo_output',\n",
    "    meas_definition_path:  os.PathLike = '../data/utility_files/measurements/measurement_defitions.yaml',\n",
    "    meas_vertices_path:  os.PathLike = '../data/utility_files/measurements/smplx_measurements.yaml',\n",
    "    smpl_model_path:  os.PathLike = 'data/body_models/smpl',\n",
    "    # render: bool = True,\n",
    ") -> None:\n",
    "\n",
    "    # device = torch.device('cuda')\n",
    "    # if not torch.cuda.is_available():\n",
    "    #     logger.error('CUDA is not available!')\n",
    "    #     sys.exit(3)\n",
    "\n",
    "    # os.makedirs(demo_output_folder, exist_ok=True)\n",
    "\n",
    "    # npz_files = sorted(os.listdir(demo_input_folder))\n",
    "    # npz_files = [x for x in npz_files if x.endswith('npz')]\n",
    "\n",
    "    body_measurements = BodyMeasurements(\n",
    "        {'meas_definition_path': meas_definition_path,\n",
    "            'meas_vertices_path': meas_vertices_path},\n",
    "    ).to('cuda')\n",
    "\n",
    "    smpl = smplx.create(\n",
    "        model_path=smpl_model_path,\n",
    "        gender=gender,\n",
    "        num_betas=num_betas,\n",
    "        model_type='smplx'\n",
    "    ).to(device)\n",
    "\n",
    "    # if render:\n",
    "    #     renderer = Renderer(\n",
    "    #         is_registration=False\n",
    "    #     )\n",
    "\n",
    "    # for npz_file in npz_files:\n",
    "    for betas in beta_sets:\n",
    "        # print(f'Processing: {npz_file}')\n",
    "\n",
    "        # read betas\n",
    "        # data = np.load(osp.join(demo_input_folder, npz_file))\n",
    "        # betas = torch.from_numpy(data['betas']).to(device).unsqueeze(0)\n",
    "\n",
    "        # smpl function & shaped body\n",
    "        body = smpl(betas=betas)\n",
    "        shaped_vertices = body['v_shaped']\n",
    "        shaped_triangles = shaped_vertices[:,smpl.faces_tensor]\n",
    "\n",
    "        # Compute the measurements on the body\n",
    "        measurements = body_measurements(shaped_triangles)['measurements']\n",
    "\n",
    "        return measurements\n",
    "        \n",
    "        # render shaped body\n",
    "        # if render:\n",
    "        #     pred_mesh = trimesh.Trimesh(shaped_vertices.cpu().numpy()[0], smpl.faces)\n",
    "        #     pred_img = renderer.render(pred_mesh)\n",
    "            \n",
    "\n",
    "        # print result\n",
    "        # mmts_str = '    Virtual measurements: '\n",
    "        # for k, v in measurements.items():\n",
    "        #     value = v['tensor'].item()\n",
    "        #     unit = 'kg' if k == 'mass' else 'm'\n",
    "        #     mmts_str += f'    {k}: {value:.2f} {unit}'\n",
    "        # print(mmts_str)\n",
    "\n",
    "        # add measurements to image and save image\n",
    "        # if render:\n",
    "        #     font = ImageFont.truetype(\"../samples/OpenSans-Regular.ttf\", size=24)\n",
    "        #     ImageDraw.Draw(pred_img).text(\n",
    "        #         (0, 10),  mmts_str, (0, 0, 0), font=font\n",
    "        #     )\n",
    "        #     pred_img.save(osp.join(demo_output_folder, npz_file.replace('npz', 'png')))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #  torch.multiprocessing.set_start_method('fork')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "    arg_formatter = argparse.ArgumentDefaultsHelpFormatter\n",
    "    description = 'PyTorch SMPL-X Regressor Demo'\n",
    "    parser = argparse.ArgumentParser(formatter_class=arg_formatter,\n",
    "                                     description=description)\n",
    "\n",
    "    parser.add_argument('--output-folder', dest='output_folder',\n",
    "                        default='demo_output', type=str,\n",
    "                        help='The folder where the demo renderings will be saved')\n",
    "    parser.add_argument('--input-folder', dest='input_folder',\n",
    "                        default='demo_input', type=str,\n",
    "                        help='The folder where the demo npz files are stored')\n",
    "    parser.add_argument('--meas_definition_path', dest='meas_definition_path',\n",
    "                        default='../data/utility_files/measurements/measurement_defitions.yaml', \n",
    "                        type=str, help='Path to measurement definitions')\n",
    "    parser.add_argument('--meas_vertices_path', dest='meas_vertices_path',\n",
    "                        default='../data/utility_files/measurements/smplx_measurements.yaml', type=str,\n",
    "                        help='Path to measurement vertices')\n",
    "    parser.add_argument('--smpl_model_path', dest='smpl_model_path',\n",
    "                        default='../data/body_models', type=str,\n",
    "                        help='Path to smpl model folder')\n",
    "    parser.add_argument('--num_betas', dest='num_betas',\n",
    "                        default=10, type=int,\n",
    "                        help='number of betas smpl model uses')\n",
    "    parser.add_argument('--gender', dest='gender',\n",
    "                        default='neutral', type=str,\n",
    "                        help='gender of smpl model')\n",
    "                        \n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main( \n",
    "        demo_input_folder=args.input_folder,\n",
    "        demo_output_folder=args.output_folder, \n",
    "        meas_definition_path=args.meas_definition_path,\n",
    "        meas_vertices_path=args.meas_vertices_path,\n",
    "        smpl_model_path=args.smpl_model_path,\n",
    "        gender=args.gender,\n",
    "        num_betas=args.num_betas\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
